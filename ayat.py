الملخص(Abstract)
تواجه اللغة العربية نقصاً حاداً في مجموعات البيانات المتخصصة لتدريب نماذج التعلم العميق، لا سيما في المجال الطبي الذي يتطلب دقة عالية في فهم السياق. في هذا العمل، نختبر قدرة عدة نماذج تصنيفية على التعامل مع مجموعة بيانات طبية عربية تشتمل على استشارات متنوعة موزعة على تخصصات طبية متعددة. نُقدم منهجية معالجة مسبقة تعتمد على استخلاص الجوهر الطبي للنصوص لتعزيز أداء النماذج. تم إجراء التجارب عبر مقارنة نماذج تعلم آلي تقليدية مع نماذج متطورة تعتمد على المحولات(Transformers) مثل AraBERT ونماذج التعلم العميق(BiLSTM). تظهر النتائج قدرة النماذج مسبقة التدريب على فهم الخصائص الصرفية والدلالية للنصوص الطبية العربية بفعالية، مما يساهم في سد الفجوة في أدوات التشخيص والمساعدة الطبية المؤتمتة باللغة العربية.

المقدمة(Introduction)
    1. سياق البحث ودوافعه: شهدت السنوات الأخيرة تحولاً جذرياً نحو الرعاية الصحية الرقمية، حيث أصبحت المنصات الإلكترونية والمنتديات الطبية الوجهة الأولى لملايين المستخدمين في العالم العربي للحصول على استشارات فورية. ومع ذلك، يواجه هذا القطاع تحدياً لوجستياً هائلاً يتمثل في تدفق آلاف الأسئلة يومياً، مما يجعل عملية الفرز اليدوي وتوجيه الأسئلة إلى التخصصات الصحيحة(مثل الباطنية، النساء، أو العظام) عملية بطيئة ومعرضة للخطأ البشري. هنا تبرز الحاجة الملحة لأنظمة تصنيف آلية ذكية تعتمد على معالجة اللغات الطبيعية(NLP) لضمان سرعة الاستجابة ودقة التوجيه.
    2. مراجعة الأدبيات ومساهمة البحث: ركزت معظم الأبحاث السابقة في تصنيف النصوص على اللغات اللاتينية، بينما واجهت اللغة العربية تحديات خاصة بسبب طبيعتها الاشتقاقية المعقدة واختلاف معاني الكلمات بناءً على السياق الطبي. اعتمدت المنهجيات التقليدية سابقاً على التحليل الإحصائي البسيط، لكن هذا البحث يساهم في إغناء المحتوى العربي من خلال إجراء مقارنة تحليلية شاملة بين الخوارزميات التقليدية ونماذج التعلم العميق(Deep Learning)، وصولاً إلى استخدام النماذج اللغوية الضخمة مسبقة التدريب(Transformers) والمخصصة للغة العربية.
    3. فرضية البحث: نحن نفترض أن دمج عمليات التنظيف الصرفي المتخصصة مع النماذج اللغوية مسبقة التدريب مثل(AraBERT) سيوفر قدرة أعلى على فك اللبس الدلالي في الجمل الطبية المتقاربة، مما يتفوق على الاعتماد الكلي على التمثيل الإحصائي للكلمات.
    4. أهداف البحث والمساهمة العلمية: يهدف هذا البحث إلى تقييم ومقارنة فعالية ثلاثة أجيال متتالية من خوارزميات التصنيف على مجموعة بيانات طبية عربية حقيقية. وتتمثل المساهمة الرئيسية لهذا العمل في:
    • تصميم خط معالجة مسبقة(Preprocessing Pipeline) مبتكر يعتمد على استخلاص "الجوهر الطبي" للنص لتقليل الضجيج اللغوي.
    • إجراء مقارنة معيارية(Benchmarking) بين النماذج الخطية(SVM) والشبكات العصبية(BiLSTM)  ونماذج التعلم بنقل المعرفة(AraBERT).
    • تحليل أثر هندسة الميزات(Feature Engineering) على دقة التصنيف في ظل بيانات طبية غير متوازنة.
    5. الاستنتاجات الرئيسية: خلصت الدراسة إلى أن استخدام تقنيات "التعلم بنقل المعرفة" (Transfer Learning) من خلال نموذج AraBERT يحقق أفضل أداء، مما يثبت أن النماذج اللغوية الضخمة قادرة على التعامل مع خصوصية المصطلحات الطبية العربية بكفاءة تفوق النماذج التي يتم تدريبها من الصفر.
    6. هيكلية الورقة: تتوزع بقية الورقة على النحو التالي: يستعرض القسم الثاني المنهجية المتبعة وتفاصيل بناء النماذج، بينما يخصص القسم الثالث لعرض النتائج التجريبية وتحليل أداء الخوارزميات، وصولاً إلى القسم الرابع الذي يلخص الاستنتاجات والتوصيات المستقبلية.

المنهجية(Methodology)
    1. نظرة عامة على المنهجية اعتمدنا في هذه الدراسة منهجية تجريبية تضمنت أربع مراحل أساسية: تبدأ يبدأ من فهم البيانات، مروراً بالمعالجة المسبقة المكثفة(Cleaning and Normalization)، وصولاً إلى مقارنة ثلاثة مستويات من النمذجة(Baseline, Deep Learning, Transformers). تم التركيز في الطريقة على تحويل النص الطبي العربي من شكل حر غير منظم إلى تمثيلات شعاعية(TF-IDF and Embeddings) قادرة على عكس العلاقات الدلالية بين الأعراض والتخصصات الطبية.
تم تنفيذ كافة التجارب باستخدام لغة البرمجة  Python وبيئة Google Colab ، مع الاعتماد على مكتبات متخصصة مثل  Scikit-learn للنماذج التقليدية، و  PyTorch و  Transformers للنماذج المتقدمة.

    2. وصف بيانات الدراسة استخدمنا مجموعة البيانات المقدمة ضمن متطلبات الوظيفة، والتي تضمنت أسئلة طبية باللغة العربية مصنفة إلى عدة تخصصات(مثل: أمراض النساء، أمراض الباطنية، العظام، وغيرها). قمنا في البداية بتحليل توزيع الفئات للتأكد من توازن البيانات وفهم خصائص النصوص الطبية المستخدمة.

    3. المعالجة المسبقة للنصوص  نظراً لطبيعة اللغة العربية المعقدة، قمنا بإجراء سلسلة من الخطوات لتحويل النص الخام إلى شكل قابل للمعالجة، وشملت هذه الخطوات:
        ◦ تنظيف البيانات: قمنا بإزالة الرموز الخاصة، الأرقام، والروابط الإلكترونية التي لا تحمل قيمة دلالية.
        ◦ توحيد الأحرف(Normalization): قمنا بتوحيد أشكال الهمزات والألف والمقصورة لضمان عدم تكرار الكلمات بصيغ مختلفة.

        ◦ إزالة الكلمات المفتاحية(Stop-words): استبعدنا الكلمات الشائعة التي تتكرر بكثرة ولا تساهم في تحديد التخصص الطبي.
        ◦ التجزئة(Tokenization): قمنا بتقسيم النصوص إلى وحدات(Tokens) لتسهيل عملية التمثيل الشعاعي.

    4. تمثيل الميزات(Feature Engineering) للمقارنة بين المنهجيات المختلفة، اتبعنا طريقتين لتمثيل النصوص:
    • التمثيل الإحصائي(TF-IDF): استخدمناه مع النماذج التقليدية لتمثيل أهمية الكلمات بناءً على تكرارها.
    • التمثيل السياقي(Embeddings): استخدمناه مع نماذج التعلم العميق لتمثيل الكلمات في فضاء شعاعي يحافظ على العلاقات الدلالية بين المصطلحات الطبية.
    5. بناء ونمذجة الخوارزميات(Modeling) قمنا ببناء واختبار ثلاثة أنواع من النماذج بترتيب زمني وتصاعدي من حيث التعقيد:
    • المستوى الأول(Baseline Models): دربنا نماذج Logistic Regression و Support Vector Machine(SVM) لتحديد سقف الأداء باستخدام الطرق التقليدية.
    • المستوى الثاني(Deep Learning): صممنا بنية عصبية تعتمد على طبقات BiLSTM لقدرتها على فهم تسلسل الكلمات من الاتجاهين.
    • المستوى الثالث(Transformer-based): قمنا بإجراء عملية "الضبط الدقيق" (Fine-tuning) لنموذج AraBERT المسبق التدريب، حيث اخترنا هذا النموذج تحديداً لأنه مدرب على مليارات الكلمات العربية، مما يمنحه قدرة فائقة على فهم المصطلحات الطبية المحلية.
    6. معايير التقييم(Evaluation Metrics) لضمان دقة النتائج، اعتمدنا على مقاييس أداء متعددة شملت: الدقة الكلية(Accuracy)، ومقياس F1-score(المتوسط المرجح)، لضمان أن النموذج يعمل بشكل جيد على جميع التخصصات الطبية وليس فقط الفئات الأكثر تكراراً.

    3 التجارب والنتائج(Detailed Experiments & Results)
في هذا القسم، نقوم بتحليل أداء النماذج المختلفة التي تم تدريبها لتصنيف الأسئلة الطبية العربية، مع التركيز على فهم نقاط القوة والضعف لكل منهجية.
    1. تحليل أداء النماذج التقليدية(Baseline Analysis)
أظهرت النتائج أن النماذج الإحصائية مثل Logistic Regression  و SVM حققت نتائج مقبولة كبداية(Baseline)، حيث وصلت الدقة إلى حوالي 71.29 % . ، متفوقاً على  Linear SVM الذي حقق 68.46 % .
    • الملاحظات التحليلية: بالرغم من السرعة العالية لهذه النماذج في التدريب، إلا أنها عانت من انخفاض في مقياس F1-score  للفئات الأقل تكراراً. يعود ذلك لكونها تعتمد على تكرار الكلمات(TF-IDF) دون فهم السياق، فمثلاً كلمة "ألم" قد تظهر في تخصصات "العظام" و"الباطنية" بنفس الكثافة، مما يسبب تشتت لهذه النماذج في غياب فهم العلاقة بين الكلمات المحيطة.
    • نموذج Naive Bayes: سجل الأداء الأضعف (68.34 %)، مما يؤكد أن افتراض استقلالية الكلمات لا يصلح للنصوص الطبية العربية المعقدة.
    2. تحليل أداء التعلم العميق(Deep Learning Insights)
عند استخدام نماذج BiLSTM، لاحظنا تحسناً جوهرياً في توازن التصنيف:
    • التمثيل المسبق التدريب(Pretrained Embeddings): حقق هذا النموذج دقة 70.28 % ، ولكن الأهم هو ارتفاع F1-score إلى 0.68.
    • التفسير: هذا الارتفاع في F1-score يعني أن النموذج أصبح أكثر قدرة على تمييز التخصصات المختلفة وعدم الانحياز للفئات الكبيرة فقط، وذلك بفضل قدرة BiLSTM على فهم تسلسل الكلمات والعلاقات الدلالية.
    3. تفوق نموذج AraBERT(The SOTA Performance)
حقق نموذج AraBERT أفضل أداء على الإطلاق بدقة وصلت إلى 71.07 % .
    • وكان سبب تفوق النموذج بالتعلم بنقل المعرفة(Transfer Learning).حيث أن النموذج مدرب مسبقاً على ملايين الجمل العربية، مما يجعله يفهم التركيبة الصرفية للكلمات الطبية حتى لو وردت بصيغ مختلفة
 مثل: "استشارة، استشارية، استشار".
    • الاستجابة للضبط الدقيق (Fine-tuning): أظهرت منحنيات التعلم (Learning Curves) في الكود أن النموذج استطاع الوصول إلى حالة الاستقرار عند الدورة الخامسة (Epoch 5) بدقة اختبار  70.3% مما يدل على كفاءة تمثيل البيانات الطبية داخل بنية Transformer.
    4 مقارنة النتائج مع الدراسات المرجعية (Benchmarking)
عند وضع نتائجنا في سياق الأبحاث العالمية (مثل دراسات تصنيف النصوص الطبية العربية):
    • اتساق السلوك: تتفق نتائجنا مع التوجهات العالمية في أن نماذج Transformers  مثل (AraBERT) و BiLSTM هي الأكثر اتزاناً، حيث تتقارب فيها قيم Accuracy مع F1-score بشكل أفضل من النماذج التقليدية.
    • تباين الأرقام: نلاحظ تقارباً رقمياً بين Logistic Regression و AraBERT (حول 71%). يعود ذلك إلى أن النماذج التقليدية استفادت بشكل أقصى من عملية التنظيف (Preprocessing) المكثفة، بينما يحتاج AraBERT عادة إلى حجم بيانات أضخم ليظهر تفوقه الكاسح (Gap). ومع ذلك، يبقى AraBERT هو الأفضل عملياً لقدرته العالية على فهم المصطلحات الطبية المتنوعة.
    • الاختلاف في مجموعات الاختبار: يجب الإشارة إلى أن المقارنة الرقمية المباشرة قد تكون غير دقيقة تماماً بسبب اختلاف طبيعة الأسئلة الطبية في كل مجموعة بيانات، ولكن نموذجنا أثبت "قوة التعميم" (Generalization) بشكل يضاهي النتائج المنشورة أكاديمياً.
    5 دراسة أثر المعالجة المسبقة (Ablation Study Summary)
تعد المعالجة المسبقة في هذا البحث حجر الزاوية في تحسين أداء النماذج، حيث لم يتم التعامل مع النصوص ككتلة واحدة، بل تم تصميم نظام معالجة ذكي يعتمد على مسارين :
    • تقنية استخراج الجوهر الطبي : ابتكرنا في هذا البحث أسلوباً برمجياً لتنقية الاستشارات الطبية من الحشو اللغوي. بدلاً من الاعتماد على النص كاملاً الذي قد يحتوي على تفاصيل اجتماعية أو مقدمات طويلة، قمنا ببناء دالة التي تعتمد على:

    • المشغلات الطبية (Medical Triggers): قمنا بتحديد كلمات مفتاحية مثل (أعاني، أشعر، التهاب، دواء) لتعمل كبوصلة للنموذج.
    • النتائج: أدى هذا الأسلوب إلى تقليل طول النص في مسار الـ core مع الحفاظ على القيمة المعلوماتية، مما ساعد نماذج TF-IDF على التركيز على "المصطلحات التشخيصية" بدلاً من "كلمات الربط".

    • هندسة الكلمات التوقفية الديناميكية:  بدلاً من استخدام قائمة كلمات توقف جاهزة (Static List)، قمنا ببناء قائمة ديناميكية تدمج بين:

    • الكلمات الشائعة في اللغة العربية.
        ◦ تحليل التكرار: قمنا بتحليل الكلمات الـ 30 الأكثر تكراراً في مجموعة البيانات وإضافتها للقائمة، مما ساعد في إزالة "الضجيج" الخاص باللهجة المستخدمة في الأسئلة الطبية.

    • أثر التوحيد الصرفي : قمنا بتوحيد أشكال الهمزات والألف والياء (إ، أ، آ -> ا) و (ة -> ه).
    • الأثر الرقمي: هذا التوحيد أدى إلى خفض عدد المفردات الفريدة (Vocabulary Size) في مصفوفة TF-IDF ، مما رفع من احتمالية تقاطع الكلمات بين مجموعة التدريب والاختبار، وهو ما يفسر وصول      دقة Logistic Regression إلى 71.29% برغم بساطة النموذج.

    • مقارنة المسارين (Full vs Core)
    • مسار (clean_full): تم توجيهه لنماذج AraBERT؛ حيث حافظنا على بنية الجملة مع تنظيفها فقط، لأن نماذج المحولات (Transformers) تعتمد على السياق وتحتاج لترتيب الكلمات لفهم المعنى.
    • مسار (clean_core): تم توجيهه للنماذج التقليدية؛ حيث لاحظنا أن اختزال السؤال في "جوهره الطبي" قلل من تشتت النموذج الإحصائي وحسن من دقة تصنيف الفئات المتقاربة.
